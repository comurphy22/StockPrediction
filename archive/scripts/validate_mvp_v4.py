"""
MVP Validation Script V4 - Financial Sentiment Classifier
Tests XGBoost with 25-feature set on 10 diverse stocks.
Uses trained FinancialPhraseBank sentiment model instead of VADER.
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime
import time
import signal
from contextlib import contextmanager

# Add src to path
src_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', 'src')
sys.path.insert(0, src_path)

from data_loader import fetch_stock_data, fetch_politician_trades
from data_loader_financial_sentiment import fetch_news_with_financial_sentiment, aggregate_daily_sentiment
from feature_engineering import create_features, handle_missing_values
from model_xgboost import train_xgboost_model, evaluate_xgboost_model
from sklearn.metrics import confusion_matrix

# Timeout context manager
class TimeoutException(Exception):
    pass

@contextmanager
def time_limit(seconds):
    """Context manager to limit execution time"""
    def signal_handler(signum, frame):
        raise TimeoutException("Timed out!")
    signal.signal(signal.SIGALRM, signal_handler)
    signal.alarm(seconds)
    try:
        yield
    finally:
        signal.alarm(0)

print("="*70)
print("MVP VALIDATION V4 - FINANCIAL SENTIMENT CLASSIFIER")
print("="*70)
print(f"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print()

# Configuration
YEAR = 2019
TRAIN_SPLIT = 0.8

# Load optimal 25 features
print("[1/4] Loading optimal feature set...")
try:
    rankings = pd.read_csv('Results/feature_importance_rankings.csv')
    top_features = rankings.head(25)['feature'].tolist()
    print(f"‚úÖ Loaded {len(top_features)} optimal features")
    print(f"   Top 5 features: {top_features[:5]}")
except Exception as e:
    print(f"‚ùå Error loading feature rankings: {e}")
    sys.exit(1)

print()

# Test stocks selection
test_stocks = [
    # High coverage stocks
    'NFLX', 'NVDA', 'BABA', 'QCOM', 'MU',
    # Major tech stocks (now with enhanced matching)
    'TSLA', 'AAPL', 'MSFT', 'GOOGL', 'AMZN'
]

print("[2/4] Test stocks selected:")
print(f"   High coverage: NFLX, NVDA, BABA, QCOM, MU")
print(f"   Major tech:    TSLA, AAPL, MSFT, GOOGL, AMZN")
print(f"   Total: {len(test_stocks)} stocks")
print(f"   üì∞ Using ENHANCED keyword matching for better news coverage")
print()

# Results storage
results = []
detailed_results = []
failed_stocks = []

# Process each stock
print("[3/4] Testing stocks...")
print("="*70)

for idx, ticker in enumerate(test_stocks, 1):
    print(f"\n[{idx}/{len(test_stocks)}] Testing {ticker}")
    print("-"*70)
    
    stock_start_time = time.time()
    
    try:
        # Step 1: Fetch stock data
        print(f"   [1/7] Fetching stock data for {YEAR}...", end=" ")
        stock_data = fetch_stock_data(ticker, f'{YEAR}-01-01', f'{YEAR}-12-31')
        print(f"‚úÖ {len(stock_data)} trading days")
        
        # Step 2: Load news sentiment with FINANCIAL CLASSIFIER
        print(f"   [2/7] Loading news with Financial Sentiment...")
        news_data = fetch_news_with_financial_sentiment(ticker, f'{YEAR}-01-01', f'{YEAR}-12-31')
        news_sentiment = aggregate_daily_sentiment(news_data)
        print(f"   ‚úÖ {len(news_data)} news items scored")
        
        # Step 3: Load politician trades (with 30s timeout)
        print(f"   [3/7] Loading politician trades...", end=" ")
        try:
            with time_limit(30):
                pol_data = fetch_politician_trades(ticker)
            print(f"‚úÖ {len(pol_data)} trades")
        except TimeoutException:
            print(f"‚è±Ô∏è  TIMEOUT after 30s, skipping {ticker}")
            failed_stocks.append({
                'ticker': ticker,
                'reason': 'Politician trades API timeout',
                'news_count': len(news_data)
            })
            continue
        except Exception as e:
            print(f"‚ùå Error: {e}")
            failed_stocks.append({
                'ticker': ticker,
                'reason': f'Error loading politician trades: {e}',
                'news_count': len(news_data)
            })
            continue
        
        # Step 4: Create features
        print(f"   [4/7] Engineering features...", end=" ")
        X_all, y_all, dates = create_features(stock_data, news_sentiment, pol_data)
        X_all = handle_missing_values(X_all)
        # Update y to match cleaned X
        y_all = y_all.loc[X_all.index]
        print(f"‚úÖ {len(X_all)} samples with {len(X_all.columns)} features")
        
        # Check if we have enough samples
        if len(X_all) < 30:
            print(f"   ‚ö†Ô∏è  Insufficient samples ({len(X_all)}), skipping {ticker}")
            continue
        
        # Step 5: Filter to top 25 features and prepare data
        print(f"   [5/7] Preparing training data...", end=" ")
        
        # Check which features are available
        available_features = [f for f in top_features if f in X_all.columns]
        missing_features = [f for f in top_features if f not in X_all.columns]
        
        if len(available_features) < 20:
            print(f"   ‚ö†Ô∏è  Too many missing features ({len(missing_features)}), skipping {ticker}")
            continue
        
        X = X_all[available_features]
        y = y_all
        
        # Train/test split (80/20)
        split_idx = int(len(X) * TRAIN_SPLIT)
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        
        print(f"‚úÖ Train: {len(X_train)}, Test: {len(X_test)}")
        
        # Step 6: Train XGBoost
        print(f"   [6/7] Training XGBoost model...", end=" ")
        model = train_xgboost_model(
            X_train, y_train,
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            verbose=False
        )
        
        # Get training accuracy
        train_pred = model.predict(X_train)
        train_acc = (train_pred == y_train).mean()
        print(f"‚úÖ Train accuracy: {train_acc:.2%}")
        
        # Step 7: Evaluate on test set
        print(f"   [7/7] Evaluating on test set...", end=" ")
        metrics = evaluate_xgboost_model(model, X_test, y_test, verbose=False)
        test_acc = metrics['accuracy']
        print(f"‚úÖ Test accuracy: {test_acc:.2%}")
        
        # Calculate additional metrics
        y_pred = model.predict(X_test)
        cm = confusion_matrix(y_test, y_pred)
        
        # Calculate overfitting gap
        overfit_gap = train_acc - test_acc
        
        # Store results
        result = {
            'ticker': ticker,
            'n_samples': len(X),
            'n_train': len(X_train),
            'n_test': len(X_test),
            'n_features': len(available_features),
            'missing_features': len(missing_features),
            'news_articles': len(news_data),
            'politician_trades': len(pol_data),
            'train_acc': train_acc,
            'test_acc': test_acc,
            'overfit_gap': overfit_gap,
            'precision': metrics['precision'],
            'recall': metrics['recall'],
            'f1': metrics['f1_score'],
            'runtime_sec': time.time() - stock_start_time
        }
        results.append(result)
        
        # Store confusion matrix
        detailed_results.append({
            'ticker': ticker,
            'tn': int(cm[0, 0]) if cm.shape == (2, 2) else 0,
            'fp': int(cm[0, 1]) if cm.shape == (2, 2) else 0,
            'fn': int(cm[1, 0]) if cm.shape == (2, 2) else 0,
            'tp': int(cm[1, 1]) if cm.shape == (2, 2) else 0
        })
        
        # Print summary
        print(f"\n   üìä Summary for {ticker}:")
        print(f"      Test Accuracy: {test_acc:.2%}")
        print(f"      Precision:     {metrics['precision']:.2%}")
        print(f"      Recall:        {metrics['recall']:.2%}")
        print(f"      F1 Score:      {metrics['f1_score']:.2%}")
        print(f"      Overfit Gap:   {overfit_gap:+.2%}")
        print(f"      News Articles: {len(news_data)} (enhanced matching)")
        print(f"      Runtime:       {result['runtime_sec']:.1f}s")
        
        # Brief pause between stocks
        if idx < len(test_stocks):
            time.sleep(2)
        
    except Exception as e:
        print(f"\n   ‚ùå Error processing {ticker}: {str(e)}")
        print(f"      Skipping to next stock...")
        continue

print("\n" + "="*70)
print("[4/4] Saving results...")
print("-"*70)

# Convert results to DataFrame
if len(results) == 0:
    print("‚ùå No results to save. All stocks failed.")
    sys.exit(1)

results_df = pd.DataFrame(results)
detailed_df = pd.DataFrame(detailed_results)

# Save detailed results
results_path = 'Results/mvp_validation_results_v4.csv'
results_df.to_csv(results_path, index=False)
print(f"‚úÖ Saved detailed results: {results_path}")

# Save confusion matrices
cm_path = 'Results/mvp_confusion_matrices_v4.csv'
detailed_df.to_csv(cm_path, index=False)
print(f"‚úÖ Saved confusion matrices: {cm_path}")

# Calculate summary statistics
summary = {
    'metric': ['mean', 'median', 'std', 'min', 'max'],
    'test_acc': [
        results_df['test_acc'].mean(),
        results_df['test_acc'].median(),
        results_df['test_acc'].std(),
        results_df['test_acc'].min(),
        results_df['test_acc'].max()
    ],
    'train_acc': [
        results_df['train_acc'].mean(),
        results_df['train_acc'].median(),
        results_df['train_acc'].std(),
        results_df['train_acc'].min(),
        results_df['train_acc'].max()
    ],
    'overfit_gap': [
        results_df['overfit_gap'].mean(),
        results_df['overfit_gap'].median(),
        results_df['overfit_gap'].std(),
        results_df['overfit_gap'].min(),
        results_df['overfit_gap'].max()
    ],
    'f1': [
        results_df['f1'].mean(),
        results_df['f1'].median(),
        results_df['f1'].std(),
        results_df['f1'].min(),
        results_df['f1'].max()
    ]
}
summary_df = pd.DataFrame(summary)

# Save summary
summary_path = 'Results/mvp_validation_summary_v4.csv'
summary_df.to_csv(summary_path, index=False)
print(f"‚úÖ Saved summary statistics: {summary_path}")

print()
print("="*70)
print("MVP VALIDATION V4 COMPLETE - FINANCIAL SENTIMENT")
print("="*70)

# Print summary statistics
print(f"\nüìä SUMMARY STATISTICS ({len(results)} stocks tested)")
print("-"*70)
print(f"Mean Test Accuracy:    {results_df['test_acc'].mean():.2%}")
print(f"Median Test Accuracy:  {results_df['test_acc'].median():.2%}")
print(f"Std Dev:               {results_df['test_acc'].std():.2%}")
print(f"Min Test Accuracy:     {results_df['test_acc'].min():.2%} ({results_df.loc[results_df['test_acc'].idxmin(), 'ticker']})")
print(f"Max Test Accuracy:     {results_df['test_acc'].max():.2%} ({results_df.loc[results_df['test_acc'].idxmax(), 'ticker']})")
print()
print(f"Mean F1 Score:         {results_df['f1'].mean():.2%}")
print(f"Mean Overfit Gap:      {results_df['overfit_gap'].mean():+.2%}")
print()

# News coverage comparison
print(f"üì∞ NEWS COVERAGE (Enhanced vs Original):")
print("-"*70)
for _, row in results_df.iterrows():
    print(f"{row['ticker']}: {row['news_articles']} articles")
print()

# Performance distribution
stocks_above_60 = (results_df['test_acc'] >= 0.60).sum()
stocks_above_65 = (results_df['test_acc'] >= 0.65).sum()
stocks_above_70 = (results_df['test_acc'] >= 0.70).sum()

print(f"üìà PERFORMANCE DISTRIBUTION")
print("-"*70)
print(f"Stocks ‚â• 70% accuracy: {stocks_above_70}/{len(results)} ({stocks_above_70/len(results)*100:.0f}%)")
print(f"Stocks ‚â• 65% accuracy: {stocks_above_65}/{len(results)} ({stocks_above_65/len(results)*100:.0f}%)")
print(f"Stocks ‚â• 60% accuracy: {stocks_above_60}/{len(results)} ({stocks_above_60/len(results)*100:.0f}%)")
print()

# MVP Target Assessment
mvp_target = 0.60
mean_acc = results_df['test_acc'].mean()

print(f"üéØ MVP TARGET ASSESSMENT")
print("-"*70)
print(f"MVP Target:            60.00%")
print(f"Achieved:              {mean_acc:.2%}")
print(f"Difference:            {(mean_acc - mvp_target)*100:+.2f} percentage points")
print()

if mean_acc >= 0.65:
    print("‚úÖ EXCELLENT: Significantly exceeds MVP target!")
    print("   Model demonstrates strong generalization with enhanced news coverage.")
elif mean_acc >= mvp_target:
    print("‚úÖ SUCCESS: Meets MVP target!")
    print("   Model shows acceptable performance across test stocks.")
else:
    print("‚ö†Ô∏è  BELOW TARGET: Needs improvement")
    print("   Enhanced news coverage improved some stocks but overall below target.")

print()
print(f"‚è±Ô∏è  Total Runtime: {sum(results_df['runtime_sec']):.1f} seconds")
print(f"üìÖ Completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print()
print("="*70)
print("COMPARISON TO V1")
print("="*70)
print("Improvements:")
print("  ‚Ä¢ MSFT: 0 ‚Üí 99 news articles")
print("  ‚Ä¢ AAPL/AMZN: Limited ‚Üí Enhanced keyword matching")
print("  ‚Ä¢ Better news coverage = More complete feature set")
print("="*70)
