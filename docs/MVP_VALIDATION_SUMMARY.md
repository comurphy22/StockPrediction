# MVP Validation Summary: V1 vs V3 vs V4

**Date:** November 4, 2025  
**Objective:** Evaluate if improved sentiment analysis enhances stock price prediction accuracy

---

## Executive Summary

After testing three validation approaches, we found that **improving sentiment analysis quality has minimal impact on model performance**. The primary bottleneck is **overfitting** (~44% gap), not sentiment quality.

### Key Findings:
- **V1 (Baseline VADER)**: 56.24% accuracy
- **V3 (Enhanced VADER with more news)**: 55.57% accuracy (-0.67%)  
- **V4 (Financial sentiment classifier)**: 56.02% accuracy (-0.22%)

**Conclusion:** More news data and better sentiment models do not improve accuracy. Overfitting must be addressed first.

---

## Version Descriptions

### V1: Baseline VADER Sentiment
- **Sentiment Model:** VADER (lexicon-based)
- **News Matching:** Direct ticker symbol only
- **Coverage:** Limited (e.g., 0 articles for AAPL, MSFT, AMZN)
- **Results:** 56.24% avg accuracy, 43.76% overfit gap

### V3: Enhanced VADER Sentiment  
- **Sentiment Model:** VADER (lexicon-based)
- **News Matching:** Ticker + company name keywords (e.g., "Apple", "Microsoft")
- **Coverage:** Significantly improved (3154 AAPL articles vs 0 in V1)
- **Results:** 55.57% avg accuracy, 44.43% overfit gap
- **Finding:** More news did NOT improve accuracy (-0.67%)

### V4: Financial Sentiment Classifier
- **Sentiment Model:** Logistic Regression trained on FinancialPhraseBank (4,846 expert-labeled sentences)
- **Training Accuracy:** 73.5% on financial text (vs VADER's general sentiment)
- **News Matching:** Same enhanced matching as V3
- **Results:** 56.02% avg accuracy (4 stocks), 43.98% overfit gap
- **Finding:** Better sentiment model shows marginal improvement (+0.45% vs V3, -0.22% vs V1)

---

## Detailed Results Comparison

### Overall Performance

| Version | Stocks Tested | Avg Accuracy | Avg Overfit Gap | Sentiment Model |
|---------|---------------|--------------|-----------------|-----------------|
| V1      | 10            | **56.24%**   | 43.76%          | VADER (baseline) |
| V3      | 9             | 55.57%       | 44.43%          | VADER (enhanced) |
| V4      | 4             | 56.02%       | 43.98%          | Financial (expert-labeled) |

### Per-Stock Comparison (Common Stocks)

| Stock | V1 Accuracy | V3 Accuracy | V4 Accuracy | Best Version | V3 News | V4 News |
|-------|-------------|-------------|-------------|--------------|---------|---------|
| BABA  | **83.87%**  | **83.87%**  | 41.94%      | V1/V3        | 450     | 450     |
| NFLX  | **57.58%**  | 54.55%      | **57.58%**  | V1/V4 (tie)  | 803     | 803     |
| NVDA  | 51.72%      | 48.28%      | **62.07%**  | V4           | 513     | 513     |

**Observations:**
- BABA: V4 performed significantly worse (41.94% vs 83.87%) - unclear why
- NFLX: V1 and V4 tied, both better than V3
- NVDA: V4 best performance (62.07%), +10% improvement

---

## Technical Implementation

### Data Loading Performance
**Problem:** V4 initially hung loading 4.6M articles (90+ seconds per stock)

**Solution:** Implemented disk caching in `data_loader_optimized.py`
- First load: 19.5s (parse 4.6M dates + save cache)
- Subsequent loads: 0.1s (**286x faster!**)

### Date Merging Fix
**Problem:** Sentiment data wasn't merging with stock data (0 overlapping dates)

**Root Cause:**
- Sentiment dates had timestamps (e.g., `2019-01-01 17:38:00`)
- Stock dates were date-only (e.g., `2019-01-01`)
- Groupby merged on exact timestamp, not date

**Solution:**
1. `aggregate_daily_sentiment()`: Added `.dt.normalize()` to remove time component before grouping
2. `feature_engineering.py`: Added `.dt.normalize()` to both stock and sentiment dates before merge

### Financial Sentiment Classifier
- **Model:** Logistic Regression + TF-IDF (5000 features, 1-2 grams)
- **Training Data:** FinancialPhraseBank (4,846 sentences)
  - 59% neutral, 28% positive, 12% negative
- **Test Accuracy:** 73.5%
- **Compound Score:** `prob_positive - prob_negative` (range: -1 to +1)

---

## Critical Insights

### 1. More News â‰  Better Accuracy
V3 dramatically increased news coverage:
- AAPL: 0 â†’ 3,154 articles
- MSFT: 0 â†’ 457 articles  
- AMZN: 0 â†’ 539 articles

Yet accuracy **decreased** by 0.67%. This suggests:
- **Data quality** matters more than quantity
- Keyword matching may introduce noise
- Model cannot leverage additional context effectively

### 2. Better Sentiment â‰  Better Predictions
FinancialPhraseBank classifier (73.5% accuracy on financial text) vs VADER:
- Understands financial language better ("setback", "plummets", "surges")
- Trained on expert-labeled data
- Yet only marginal improvement (+0.45% vs V3)

**Implication:** Sentiment quality is not the bottleneck.

### 3. Overfitting Is The Primary Bottleneck
**All versions suffer from severe overfitting:**
- Train accuracy: ~100% (perfect memorization)
- Test accuracy: ~56% (poor generalization)
- **Gap: ~44%**

This indicates:
- Model is too complex (max_depth=6 too high)
- Not enough regularization
- Possibly too many features (41 total, using 25)

---

## Recommendations

### Priority 1: Address Overfitting (CRITICAL)
**Current XGBoost params:**
```python
max_depth=6
learning_rate=0.1
n_estimators=100
```

**Recommended experiments:**
1. **Reduce max_depth:** Try 3, 4 (from 6)
2. **Add regularization:** 
   - `alpha` (L1): Try 0.1, 1.0
   - `lambda` (L2): Try 1.0, 10.0
3. **Increase min_child_weight:** Try 3, 5 (from 1)
4. **Early stopping:** Monitor validation loss

**Expected impact:** Reduce gap from 44% to 20-30%

### Priority 2: Feature Engineering
- Analyze which of 25 features contribute to overfitting
- Consider dimensionality reduction (PCA)
- Test simpler feature sets (10-15 features)

### Priority 3: Model Alternatives (Lower Priority)
Since overfitting is the issue, try inherently regularized models:
- **Random Forest** (built-in bagging)
- **Ridge/Lasso Regression** (linear, interpretable)
- **LightGBM** (better regularization than XGBoost)

### Deprioritize: Sentiment Improvements
Given minimal impact, **do not** invest more time in:
- Better sentiment models
- More news data
- Alternative sentiment APIs

---

## Experimental Results

### FinancialPhraseBank Classifier Details
**Training:**
- Dataset: 4,846 financial sentences (59% neutral, 28% pos, 12% neg)
- Preprocessing: Lowercase, remove special chars, normalize whitespace
- Vectorization: TF-IDF (max 5000 features, 1-2 grams)
- Model: Logistic Regression (balanced class weights)
- Train/test split: 80/20

**Performance:**
```
Test Accuracy: 73.5%

Classification Report:
              precision    recall  f1-score   support
    negative       0.71      0.59      0.64       115
     neutral       0.75      0.84      0.79       584
    positive       0.66      0.55      0.60       271
```

**Example Predictions:**
- "Company announces record profits" â†’ Positive (0.85 confidence)
- "Stock faces regulatory setback" â†’ Negative (0.78 confidence)  
- "Quarterly earnings meet expectations" â†’ Neutral (0.82 confidence)

### V4 Validation (Partial Results)
Only 4/10 stocks completed due to API timeouts:

| Stock | Accuracy | Overfit Gap | News Articles | Runtime |
|-------|----------|-------------|---------------|---------|
| NFLX  | 57.58%   | +42.42%     | 803           | 2.9s    |
| NVDA  | 62.07%   | +37.93%     | 513           | 1.0s    |
| BABA  | 41.94%   | +58.06%     | 450           | 0.8s    |
| QCOM  | 62.50%   | +37.50%     | 434           | 0.8s    |

**Issues encountered:**
- Politician trades API timeouts (MU, TSLA, etc.)
- Financial sentiment classifier hanging on large batches (800+ headlines)

---

## Conclusion

**Three validation iterations demonstrate that improving sentiment analysis (V3, V4) does not significantly improve stock prediction accuracy.** The model is severely overfitting to training data (~100% train, ~56% test), which must be addressed before any other improvements.

**Next steps:**
1. âœ… Validated hypothesis: Sentiment quality is not the bottleneck
2. âš ï¸  **Action required:** Fix overfitting (reduce max_depth, add regularization)
3. ðŸ”„ Re-validate after overfitting fixes
4. ðŸ“Š Consider simpler models or feature sets

The journey from V1 â†’ V3 â†’ V4 has been valuable in ruling out sentiment as the primary issue. Now we can focus efforts on the real problem: model complexity and generalization.

---

## Files Generated

### Data Loaders
- `src/data_loader.py` - Baseline VADER (V1)
- `src/data_loader_enhanced.py` - Enhanced keyword matching
- `src/data_loader_optimized.py` - Pre-indexed datasets with caching (V3)
- `src/data_loader_financial_sentiment.py` - Financial classifier (V4)

### Models
- `models/financial_sentiment_classifier.pkl` - Trained LogisticRegression
- `models/financial_sentiment_vectorizer.pkl` - TF-IDF vectorizer

### Validation Scripts
- `scripts/validate_mvp.py` - V1 baseline
- `scripts/validate_mvp_v2.py` - (not used)
- `scripts/validate_mvp_v3.py` - V3 enhanced VADER
- `scripts/validate_mvp_v4.py` - V4 financial sentiment

### Results
- `results/mvp_validation_results.csv` - V1 results (10 stocks)
- `results/mvp_validation_results_v2.csv` - V3 results (9 stocks)
- `results/mvp_validation_results_v4_partial.csv` - V4 results (4 stocks)

### Logs
- `logs/mvp_validation.log` - V1 execution log
- `logs/mvp_validation_v3.log` - V3 execution log
- `logs/mvp_validation_v4.log` - V4 execution log

---

## Technical Debt

1. **API Reliability:** Politician trades API frequently times out (>30s)
2. **Financial Sentiment Scaling:** Classifier hangs on batches of 800+ headlines
3. **Incomplete V4 Results:** Only 4/10 stocks completed
4. **Date Timezone Handling:** Stock data has timezones, sentiment doesn't (now normalized)
5. **Cache Invalidation:** No mechanism to refresh cached data (4.6M articles)

---

**End of Report**
